{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bf826011b11c83d",
   "metadata": {},
   "source": [
    "### 1. Setup and Imports \n",
    "\n",
    "This section initializes the environment, sets up necessary constants, and imports required libraries and modules."
   ]
  },
  {
   "cell_type": "code",
   "id": "5d9806df48a0302f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T13:27:53.230908Z",
     "start_time": "2024-06-01T13:27:53.160307Z"
    }
   },
   "source": [
    "from typing import Optional\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import  Dict\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from database.mongo_helper import MongoDBConnection\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from numpy import ndarray\n",
    "from common.constants import Locations\n",
    "from common.file_utilities import FileUtilities\n",
    "from database.chroma_helper import ChromaHelper\n",
    "from text_processors.antique_text_processor import AntiqueTextProcessor\n",
    "from tabulate import tabulate\n",
    "from typing import List\n",
    "from overrides import overrides\n",
    "from typing import List\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag, PorterStemmer, ne_chunk\n",
    "from nltk.corpus import wordnet\n",
    "import string\n",
    "from spellchecker import SpellChecker\n",
    "import re\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "ANTIQUE_DATASET_PATH = os.getenv('ANTIQUE_DATASET_PATH')\n",
    "RECALL_PRECISION_THRESHOLD = int(os.getenv('RECALL_PRECISION_THRESHOLD', 10))\n"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "id": "196a4afe635654d5",
   "metadata": {},
   "source": [
    "### 2. Define Evaluation Metrics Calculators\n",
    "\n",
    "in this section we are creating the routines used to calculate evaluations later for MAP, MRR, Recall@10, precision@10"
   ]
  },
  {
   "cell_type": "code",
   "id": "9e34349102fe78b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T13:27:53.262290Z",
     "start_time": "2024-06-01T13:27:53.234916Z"
    }
   },
   "source": [
    "class MetricCalculator(ABC):\n",
    "    @abstractmethod\n",
    "    def calculate(self, query_id: str, retrieved_docs: List[str], qrels: Dict[str, Dict[str, int]], k: Optional[int] = None) -> float:\n",
    "        pass\n",
    "\n",
    "class AveragePrecisionCalculator(MetricCalculator):\n",
    "    def calculate(self, query_id: str, retrieved_docs: List[str], qrels: Dict[str, Dict[str, int]], k: Optional[int] = None) -> float:\n",
    "        if query_id not in qrels:\n",
    "            return 0.0\n",
    "\n",
    "        relevant_docs = qrels[query_id]\n",
    "        num_retrieved_relevant_docs = 0\n",
    "        sum_precisions = 0.0\n",
    "        num_relevant_docs = 0\n",
    "\n",
    "        for i, doc_id in enumerate(retrieved_docs, start=1):\n",
    "            if doc_id in relevant_docs and relevant_docs[doc_id] > 0:\n",
    "                num_retrieved_relevant_docs += 1\n",
    "                num_relevant_docs += 1\n",
    "                precision_at_i = num_retrieved_relevant_docs / i\n",
    "                sum_precisions += precision_at_i\n",
    "\n",
    "        average_precision = 0 if num_relevant_docs == 0 else sum_precisions / num_relevant_docs\n",
    "        return average_precision\n",
    "\n",
    "class PrecisionCalculator(MetricCalculator):\n",
    "    def calculate(self, query_id: str, retrieved_docs: List[str], qrels: Dict[str, Dict[str, int]], k: Optional[int] = None) -> float:\n",
    "        if not retrieved_docs:\n",
    "            return 0.0\n",
    "\n",
    "        relevant_docs = qrels.get(query_id, {})\n",
    "        relevant_retrieved = sum(1 for doc_id in retrieved_docs[:k] if doc_id in relevant_docs)\n",
    "\n",
    "        if not relevant_retrieved:\n",
    "            return 0.0\n",
    "        denominator = min(len(retrieved_docs), k)\n",
    "        if denominator == 0:\n",
    "            return 0.0\n",
    "        precision = relevant_retrieved / denominator\n",
    "        return precision\n",
    "       \n",
    "\n",
    "class RecallCalculator(MetricCalculator):\n",
    "    def calculate(self, query_id: str, retrieved_docs: List[str], qrels: Dict[str, Dict[str, int]], k: Optional[int] = None) -> float:\n",
    "        relevant_docs = qrels.get(query_id, {})\n",
    "        relevant_retrieved = sum(1 for doc_id in retrieved_docs[:k] if doc_id in relevant_docs)\n",
    "        total_relevant = sum(relevant_docs.values())\n",
    "        return relevant_retrieved / total_relevant if total_relevant > 0 else 0\n",
    "\n",
    "class ReciprocalRankCalculator(MetricCalculator):\n",
    "    def calculate(self, query_id: str, retrieved_docs: List[str], qrels: Dict[str, Dict[str, int]], k: Optional[int] = None) -> float:\n",
    "        relevant_docs = qrels.get(query_id, {})\n",
    "\n",
    "        if k is not None:\n",
    "            retrieved_docs = retrieved_docs[:k]\n",
    "\n",
    "        for i, doc in enumerate(retrieved_docs, start=1):\n",
    "            doc_id = doc['doc_id']\n",
    "            if doc_id in relevant_docs.keys() and relevant_docs[doc_id] > 0:\n",
    "                return 1.0 / i\n",
    "        return 0.0\n"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "id": "a5b73f06a112b76f",
   "metadata": {},
   "source": [
    "### 3. Define Evaluation Manager\n",
    "EvaluationManager is an extra class responsible for evaluating the qrels & queries passed for a set of (matcher, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "id": "60888a3505939500",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T13:27:53.278650Z",
     "start_time": "2024-06-01T13:27:53.266300Z"
    }
   },
   "source": [
    "class EvaluationManager:\n",
    "    def __init__(self, metric_calculators: List[MetricCalculator], matcher):\n",
    "        self.metric_calculators = metric_calculators\n",
    "        self.matcher = matcher\n",
    "\n",
    "    def evaluate(self, queries: Dict[str, str], qrels: Dict[str, Dict[str, int]], k: Optional[int] = None) -> Dict[str, Dict[str, float]]:\n",
    "        evaluation_results = {}\n",
    "\n",
    "        for query_id, query_text in queries.items():\n",
    "            retrieved_docs = self.matcher.match(query_text)[:k]\n",
    "            metrics_results = {}\n",
    "            for metric_calculator in self.metric_calculators:\n",
    "                metric_name = metric_calculator.__class__.__name__\n",
    "                if metric_name in [\"AveragePrecisionCalculator\", \"RecallCalculator\", \"PrecisionCalculator\"]:\n",
    "                    retrieved_doc_ids = [doc_info['doc_id'] for doc_info in retrieved_docs]\n",
    "                    metric_value = metric_calculator.calculate(query_id, retrieved_doc_ids, qrels, k=k)\n",
    "                else:\n",
    "                    metric_value = metric_calculator.calculate(query_id, retrieved_docs, qrels)\n",
    "                metrics_results[metric_name] = metric_value\n",
    "\n",
    "            evaluation_results[query_id] = metrics_results\n",
    "\n",
    "        return evaluation_results\n"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "id": "4f193abee2a91b30",
   "metadata": {},
   "source": [
    "### 4. Load Data\n",
    "in this section we are loading the trained model `load_as_dict`, qrels, and queries."
   ]
  },
  {
   "cell_type": "code",
   "id": "9b267bbe2cda9b13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T13:27:53.325113Z",
     "start_time": "2024-06-01T13:27:53.280656Z"
    }
   },
   "source": [
    "class DatasetReader:\n",
    "    def __init__(self, file_path: str):\n",
    "        self.file_path = file_path\n",
    "\n",
    "    @abstractmethod\n",
    "    def load_as_dict(self) -> dict:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def read_queries(self) -> dict:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def read_qrels(self) -> defaultdict:\n",
    "        pass\n",
    "    \n",
    "class AntiqueReader(DatasetReader):\n",
    "    @overrides\n",
    "    def load_as_dict(self) -> dict:\n",
    "        key_value_pairs = {}\n",
    "        with open(self.file_path, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                key, value = line.strip().split('\\t')\n",
    "                key_value_pairs[key] = value\n",
    "        return key_value_pairs\n",
    "\n",
    "    @overrides\n",
    "    def read_queries(self) -> dict:\n",
    "        queries_path = os.environ.get('ANTIQUE_QUERIES_PATH')\n",
    "        queries = {}\n",
    "        with open(queries_path, 'r') as f:\n",
    "            for line in f:\n",
    "                query_id, query_text = line.strip().split('\\t')\n",
    "                queries[query_id] = query_text\n",
    "        return queries\n",
    "\n",
    "    @overrides\n",
    "    def read_qrels(self) -> defaultdict:\n",
    "        qrels_path = os.environ.get('ANTIQUE_QRELS_PATH')\n",
    "        qrels = defaultdict(dict)\n",
    "        with open(qrels_path, 'r') as f:\n",
    "            for line_num, line in enumerate(f, 1):\n",
    "                parts = re.split(r'\\s+', line.strip())\n",
    "\n",
    "                query_id, _, doc_id, relevance = parts\n",
    "                qrels[query_id][doc_id] = int(relevance)\n",
    "\n",
    "        return qrels\n",
    "    \n",
    "def load_antique_data():\n",
    "    reader = AntiqueReader(ANTIQUE_DATASET_PATH)\n",
    "    qrels = reader.read_qrels()\n",
    "    queries = reader.read_queries()\n",
    "    return qrels, queries\n",
    "\n",
    "qrels, queries = load_antique_data()"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5. Text Processing\n",
    "text processing steps used for training the model and preparing queries"
   ],
   "id": "1d11aedf72f6f43f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T13:27:53.364106Z",
     "start_time": "2024-06-01T13:27:53.328123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def get_wordnet_pos(tag_parameter):\n",
    "    tag = tag_parameter[0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "\n",
    "class BaseTextProcessor:\n",
    "    def __init__(self) -> None:\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.spell_checker = SpellChecker(distance=4)\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.tokenizer = word_tokenize\n",
    "        self.stemmer = PorterStemmer()\n",
    "        self.pos_tagger = pos_tag\n",
    "\n",
    "    def process(self, text) -> List[str]:\n",
    "        pass\n",
    "\n",
    "    def process_query(self, query: str) -> List[str]:\n",
    "        pass\n",
    "\n",
    "    def _word_tokenizer(self, text: str) -> List[str]:\n",
    "        tokens = self.tokenizer(text)\n",
    "        return tokens\n",
    "\n",
    "    @staticmethod\n",
    "    def _lowercase_tokens(tokens: List[str]) -> List[str]:\n",
    "        return [str(np.char.lower(token)) for token in tokens]\n",
    "\n",
    "    def _filter_stop_words(self, tokens: List[str]) -> List[str]:\n",
    "        return [token for token in tokens if token not in self.stop_words and len(token) > 1]\n",
    "\n",
    "    @staticmethod\n",
    "    def _remove_registered_markers(tokens: List[str]) -> List[str]:\n",
    "        return [re.sub(r'\\u00AE', '', token) for token in tokens if token is not None]\n",
    "\n",
    "    @staticmethod\n",
    "    def _strip_punctuation(tokens: List[str]) -> List[str]:\n",
    "        return [\n",
    "            token.translate(str.maketrans('', '', string.punctuation))\n",
    "            for token in tokens if token is not None\n",
    "        ]\n",
    "\n",
    "    @staticmethod\n",
    "    def _eliminate_whitespaces(tokens: List[str]) -> List[str]:\n",
    "        return [re.sub(r'_', ' ', token) for token in tokens if token is not None]\n",
    "\n",
    "    @staticmethod\n",
    "    def _remove_apostrophes(tokens: List[str]) -> List[str]:\n",
    "        return [str(np.char.replace(token, \"'\", \" \")) for token in tokens if token is not None]\n",
    "\n",
    "    def _apply_stemming(self, tokens: List[str]) -> List[str]:\n",
    "        return [self.stemmer.stem(token) for token in tokens]\n",
    "\n",
    "    @staticmethod\n",
    "    def _normalize_abbreviations(tokens: List[str]) -> List[str]:\n",
    "        resolved_terms = {}\n",
    "        for token in tokens:\n",
    "\n",
    "            if len(token) >= 2:\n",
    "                synsets = wordnet.synsets(token)\n",
    "                if synsets:\n",
    "                    resolved_term = synsets[0].lemmas()[0].name()\n",
    "                    resolved_terms[token] = resolved_term\n",
    "\n",
    "        for abbreviation, resolved_term in resolved_terms.items():\n",
    "            for i in range(len(tokens)):\n",
    "                if tokens[i] == abbreviation:\n",
    "                    tokens[i] = resolved_term\n",
    "                    break\n",
    "\n",
    "        return tokens\n",
    "\n",
    "    def _lemmatize_tokens(self, tokens: List[str]) -> List[str]:\n",
    "        lemmatizer = self.lemmatizer\n",
    "        pos_tags = self.pos_tagger(tokens)\n",
    "        lemmatized_tokens = [lemmatizer.lemmatize(token, pos=get_wordnet_pos(tag)) for token, tag in pos_tags]\n",
    "        return lemmatized_tokens\n",
    "\n",
    "    def _spell_check(self, tokens: List[str]) -> List[str]:\n",
    "        return [self.spell_checker.correction(word) if isinstance(word, str) else word for word in tokens if\n",
    "                word is not None]\n",
    "    @staticmethod\n",
    "    def get_tokens_as_string(tokens: List[str]) -> str:\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "    def _apply_named_entity_recognition(self, tokens: List[str]) -> List[str]:\n",
    "        tagged_tokens = self.pos_tagger(tokens)\n",
    "        ner_tags = ne_chunk(tagged_tokens)\n",
    "        entities = []\n",
    "\n",
    "        def extract_entity_text(chunk):\n",
    "            if isinstance(chunk, nltk.tree.Tree):\n",
    "                return ' '.join([extract_entity_text(c) for c in chunk])\n",
    "            else:\n",
    "                return chunk[0]\n",
    "\n",
    "        for chunk in ner_tags:\n",
    "            if hasattr(chunk, 'label') and chunk.label() == 'NE':\n",
    "                entity = extract_entity_text(chunk.leaves())\n",
    "                entities.append(str(entity))\n",
    "            else:\n",
    "                entity = chunk[0] if isinstance(chunk, nltk.tree.Tree) else chunk[0][0]\n",
    "                entities.append(str(entity))\n",
    "\n",
    "        return entities\n",
    "\n",
    "class AntiqueTextProcessor(BaseTextProcessor):\n",
    "    @overrides\n",
    "    def process(self, text) -> List[str]:\n",
    "        tokens = self._word_tokenizer(text)\n",
    "        tokens = self._lowercase_tokens(tokens)\n",
    "        tokens = self._strip_punctuation(tokens)\n",
    "        tokens = self._remove_apostrophes(tokens)\n",
    "        tokens = self._filter_stop_words(tokens)\n",
    "        tokens = self._remove_registered_markers(tokens)\n",
    "        tokens = self._lemmatize_tokens(tokens)\n",
    "        tokens = self._normalize_abbreviations(tokens)\n",
    "        tokens = self._lowercase_tokens(tokens)\n",
    "        tokens = self._eliminate_whitespaces(tokens)\n",
    "        return tokens"
   ],
   "id": "a63a1e4c4ac754c8",
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "id": "1a5017919bdc6854",
   "metadata": {},
   "source": [
    "### 6. Matching\n",
    "matcher classes are used to match a query to a set of documents, it calculates the similarity between query and document using `cos_similarity`"
   ]
  },
  {
   "cell_type": "code",
   "id": "24e40c57def6d18e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T13:27:53.378603Z",
     "start_time": "2024-06-01T13:27:53.367114Z"
    }
   },
   "source": [
    "class QueryMatcher:\n",
    "    def __init__(self, model_name: str):\n",
    "        matrix_path: str = Locations.generate_matrix_path(model_name)\n",
    "        self.matrix = FileUtilities.load_file(matrix_path)\n",
    "\n",
    "        model_path: str = Locations.generate_model_path(model_name)\n",
    "        self.model: TfidfVectorizer = FileUtilities.load_file(model_path)\n",
    "\n",
    "        self.threshold = float(os.environ.get('SIMILARITY_THRESHOLD', 0.1))\n",
    "\n",
    "        self.db_collection = MongoDBConnection.get_instance().get_collection(model_name)\n",
    "\n",
    "    def __vectorize_query(self, query: str):\n",
    "        return self.model.transform([query])\n",
    "\n",
    "    def match(self, query: str):\n",
    "        query_vector = self.__vectorize_query(query)\n",
    "\n",
    "        cos_similarities = cosine_similarity(self.matrix, query_vector)\n",
    "\n",
    "        sorted_indices = np.argsort(cos_similarities, axis=0)[::-1].flatten()\n",
    "\n",
    "        matching_docs_indices = []\n",
    "        for i in sorted_indices:\n",
    "            if cos_similarities[i].item() >= self.threshold:\n",
    "                matching_docs_indices.append(i.item() + 1)\n",
    "\n",
    "        matching_results = list(self.db_collection.find({\"index\": {\"$in\": matching_docs_indices}}))\n",
    "\n",
    "        return sorted(\n",
    "            matching_results,\n",
    "            key=lambda x: matching_docs_indices.index(x['index']),\n",
    "            reverse=False\n",
    "        )\n",
    "    \n",
    "\n",
    "class AntiqueMatcher(QueryMatcher):\n",
    "    def __init__(self):\n",
    "        super().__init__(Locations.ANTIQUE_COLLECTION_NAME)"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "id": "9e5b9f0b03b79561",
   "metadata": {},
   "source": "### 7. Results (Without Embedding)"
  },
  {
   "cell_type": "code",
   "id": "432eac22ce0317ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T13:30:24.412123Z",
     "start_time": "2024-06-01T13:27:53.380611Z"
    }
   },
   "source": [
    "matcher = AntiqueMatcher()\n",
    "\n",
    "metric_calculators = [\n",
    "    AveragePrecisionCalculator(),\n",
    "    PrecisionCalculator(),\n",
    "    RecallCalculator(),\n",
    "    ReciprocalRankCalculator()\n",
    "]\n",
    "\n",
    "evaluation_manager = EvaluationManager(metric_calculators, matcher)\n",
    "evaluation_results_no_embedding = evaluation_manager.evaluate(queries, qrels, RECALL_PRECISION_THRESHOLD)\n",
    "\n",
    "def calculate_average_metrics(evaluation_results):\n",
    "    total_map = sum(metrics_results[\"AveragePrecisionCalculator\"] for metrics_results in evaluation_results.values())\n",
    "    total_mrr = sum(metrics_results[\"ReciprocalRankCalculator\"] for metrics_results in evaluation_results.values())\n",
    "    total_queries = len(evaluation_results)\n",
    "\n",
    "    average_map = total_map / total_queries if total_queries > 0 else 0.0\n",
    "    average_mrr = total_mrr / total_queries if total_queries > 0 else 0.0\n",
    "\n",
    "    return average_map, average_mrr\n",
    "\n",
    "average_map_no_embedding, average_mrr_no_embedding = calculate_average_metrics(evaluation_results_no_embedding)\n",
    "print(f\"MAP without embedding: {average_map_no_embedding}\")\n",
    "print(f\"MRR without embedding: {average_mrr_no_embedding}\")\n",
    "\n",
    "table = []\n",
    "for query_id, metrics in evaluation_results_no_embedding.items():\n",
    "    row = [\n",
    "        query_id,\n",
    "        f\"{metrics['PrecisionCalculator']}\",\n",
    "        f\"{metrics['RecallCalculator']:.6f}\"\n",
    "    ]\n",
    "    table.append(row)\n",
    "\n",
    "print(\"\\nDetailed Results Without Embedding:\")\n",
    "print(tabulate(table, headers=[\"Query ID\", f'Precision@{RECALL_PRECISION_THRESHOLD}', f'Recall@{RECALL_PRECISION_THRESHOLD}'], tablefmt=\"pretty\"))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP without embedding: 0.5943830183925422\n",
      "MRR without embedding: 0.687845238095238\n",
      "\n",
      "Detailed Results Without Embedding:\n",
      "+----------+--------------+-----------+\n",
      "| Query ID | Precision@10 | Recall@10 |\n",
      "+----------+--------------+-----------+\n",
      "| 3990512  |     0.6      | 0.082192  |\n",
      "|  714612  |     0.3      | 0.042857  |\n",
      "| 2528767  |     0.6      | 0.083333  |\n",
      "|  821387  |     0.2      | 0.018868  |\n",
      "| 1880028  |     0.7      | 0.104478  |\n",
      "| 4448097  |     0.5      | 0.069444  |\n",
      "| 1287437  |     0.2      | 0.025316  |\n",
      "| 2956570  |     0.6      | 0.107143  |\n",
      "| 1351675  |     0.2      | 0.037736  |\n",
      "| 1783010  |     0.0      | 0.000000  |\n",
      "| 2799913  |     0.3      | 0.033708  |\n",
      "| 2142044  |     0.9      | 0.191489  |\n",
      "|  707303  |     0.1      | 0.012987  |\n",
      "|  676028  |     0.4      | 0.061538  |\n",
      "| 2484180  |     0.3      | 0.037975  |\n",
      "| 2307305  |     0.1      | 0.013699  |\n",
      "| 2814599  |     0.6      | 0.133333  |\n",
      "| 3369088  |     0.1      | 0.009346  |\n",
      "| 1702151  |     0.3      | 0.055556  |\n",
      "|  851124  |     0.2      | 0.027027  |\n",
      "| 3698636  |     0.1      | 0.009346  |\n",
      "| 1844896  |     0.1      | 0.015873  |\n",
      "| 2290758  |     0.1      | 0.011765  |\n",
      "|  143833  |     0.5      | 0.089286  |\n",
      "| 3910925  |     0.5      | 0.042017  |\n",
      "| 2643507  |     0.6      | 0.075949  |\n",
      "| 1502604  |     0.0      | 0.000000  |\n",
      "| 4283542  |     0.4      | 0.062500  |\n",
      "| 3554263  |     0.1      | 0.011236  |\n",
      "| 3313308  |     0.0      | 0.000000  |\n",
      "| 4357460  |     0.2      | 0.020619  |\n",
      "| 2582920  |     1.0      | 0.117647  |\n",
      "| 4462511  |     0.1      | 0.020000  |\n",
      "| 2795030  |     0.2      | 0.024691  |\n",
      "|  312215  |     0.5      | 0.079365  |\n",
      "| 3363149  |     0.4      | 0.074074  |\n",
      "| 1944018  |     0.2      | 0.017094  |\n",
      "|  788976  |     0.1      | 0.009009  |\n",
      "| 4385316  |     0.2      | 0.027027  |\n",
      "|  551239  |     0.6      | 0.082192  |\n",
      "| 3499881  |     0.4      | 0.042553  |\n",
      "| 4311093  |     0.7      | 0.076087  |\n",
      "| 4256593  |     0.4      | 0.065574  |\n",
      "| 1017690  |     0.3      | 0.062500  |\n",
      "|  667488  |     1.0      | 0.270270  |\n",
      "| 3507491  |     0.3      | 0.036145  |\n",
      "| 2634143  |     0.9      | 0.209302  |\n",
      "| 3396066  |     0.1      | 0.009901  |\n",
      "| 2892478  |     0.3      | 0.046875  |\n",
      "| 3155314  |     0.0      | 0.000000  |\n",
      "|  785823  |     0.0      | 0.000000  |\n",
      "| 2815090  |     0.4      | 0.072727  |\n",
      "| 2713171  |     0.0      | 0.000000  |\n",
      "| 1821193  |     0.3      | 0.037037  |\n",
      "| 4185501  |     0.5      | 0.050505  |\n",
      "| 4473331  |     0.1      | 0.014706  |\n",
      "| 4190287  |     0.2      | 0.029851  |\n",
      "| 1937374  |     0.2      | 0.029412  |\n",
      "| 1459749  |     0.4      | 0.085106  |\n",
      "|  23464   |     0.2      | 0.035714  |\n",
      "| 4377861  |     0.5      | 0.217391  |\n",
      "| 3385681  |     0.4      | 0.036036  |\n",
      "| 1794677  |     0.2      | 0.025000  |\n",
      "| 3301173  |     0.2      | 0.042553  |\n",
      "|  204633  |     0.2      | 0.030769  |\n",
      "| 3960080  |     0.5      | 0.096154  |\n",
      "| 1262692  |     0.1      | 0.010204  |\n",
      "|  558570  |     0.3      | 0.043478  |\n",
      "| 1167882  |     0.1      | 0.016949  |\n",
      "| 3295055  |     0.4      | 0.057143  |\n",
      "|  100653  |     0.9      | 0.150000  |\n",
      "| 2619912  |     0.0      | 0.000000  |\n",
      "| 1663853  |     0.1      | 0.011628  |\n",
      "| 2592121  |     0.3      | 0.040541  |\n",
      "| 2182052  |     0.6      | 0.111111  |\n",
      "| 1623623  |     0.1      | 0.014706  |\n",
      "| 3078448  |     0.0      | 0.000000  |\n",
      "| 3074429  |     0.2      | 0.020408  |\n",
      "| 1119420  |     0.2      | 0.024691  |\n",
      "| 1290612  |     0.3      | 0.036145  |\n",
      "| 2529114  |     0.6      | 0.056604  |\n",
      "|  204963  |     0.0      | 0.000000  |\n",
      "| 4367654  |     0.1      | 0.013889  |\n",
      "| 3639660  |     0.0      | 0.000000  |\n",
      "| 4197214  |     0.7      | 0.085366  |\n",
      "| 1015624  |     0.4      | 0.063492  |\n",
      "| 1082595  |     0.3      | 0.057692  |\n",
      "| 3239329  |     0.3      | 0.045455  |\n",
      "| 3874326  |     0.3      | 0.046875  |\n",
      "| 1254390  |     0.4      | 0.047619  |\n",
      "| 4018891  |     0.4      | 0.019324  |\n",
      "| 3552010  |     0.2      | 0.027027  |\n",
      "| 1968489  |     0.1      | 0.013514  |\n",
      "|  443848  |     0.8      | 0.121212  |\n",
      "| 4372730  |     0.0      | 0.000000  |\n",
      "|  896725  |     0.1      | 0.011494  |\n",
      "| 2180086  |     0.0      | 0.000000  |\n",
      "|  34041   |     0.2      | 0.019417  |\n",
      "|  229303  |     0.3      | 0.032258  |\n",
      "| 2446614  |     0.2      | 0.020202  |\n",
      "|  654124  |     0.2      | 0.025316  |\n",
      "| 3577501  |     0.5      | 0.076923  |\n",
      "|   8293   |     0.1      | 0.016393  |\n",
      "| 4012558  |     0.3      | 0.047619  |\n",
      "|  922849  |     0.7      | 0.049296  |\n",
      "| 2976644  |     0.3      | 0.047619  |\n",
      "| 1866981  |     0.0      | 0.000000  |\n",
      "| 4467100  |     0.0      | 0.000000  |\n",
      "| 2551845  |     0.4      | 0.043011  |\n",
      "| 3559048  |     0.4      | 0.060606  |\n",
      "|  823384  |     0.4      | 0.081633  |\n",
      "|  849221  |     0.2      | 0.018519  |\n",
      "| 3280768  |     0.1      | 0.010638  |\n",
      "| 4288761  |     0.4      | 0.043011  |\n",
      "| 2847807  |     0.3      | 0.033708  |\n",
      "| 2018562  |     0.4      | 0.057143  |\n",
      "| 1035857  |     0.2      | 0.022472  |\n",
      "| 2008017  |     0.2      | 0.025000  |\n",
      "| 1862795  |     0.3      | 0.060000  |\n",
      "|  421753  |     0.0      | 0.000000  |\n",
      "| 1477322  |     0.0      | 0.000000  |\n",
      "| 1607728  |     0.5      | 0.070423  |\n",
      "|  103830  |     0.3      | 0.045455  |\n",
      "| 3971195  |     0.9      | 0.070312  |\n",
      "| 4153592  |     0.1      | 0.010638  |\n",
      "| 2382487  |     0.0      | 0.000000  |\n",
      "| 2380990  |     0.5      | 0.056818  |\n",
      "|  484496  |     0.0      | 0.000000  |\n",
      "| 4003223  |     0.4      | 0.056338  |\n",
      "| 4185395  |     0.8      | 0.094118  |\n",
      "| 1292734  |     0.0      | 0.000000  |\n",
      "| 3389038  |     0.4      | 0.046512  |\n",
      "|  474417  |     0.6      | 0.086957  |\n",
      "| 3278654  |     0.7      | 0.074468  |\n",
      "| 4365565  |     0.1      | 0.013158  |\n",
      "|  354733  |     0.2      | 0.030769  |\n",
      "|  224109  |     0.0      | 0.000000  |\n",
      "| 4126337  |     0.2      | 0.034483  |\n",
      "| 1957887  |     0.4      | 0.054795  |\n",
      "|  78762   |     0.0      | 0.000000  |\n",
      "|  159716  |     0.4      | 0.053333  |\n",
      "|  481173  |     0.7      | 0.070000  |\n",
      "| 2814722  |     0.5      | 0.056180  |\n",
      "| 3040435  |     0.2      | 0.040816  |\n",
      "|  953489  |     0.0      | 0.000000  |\n",
      "| 2309774  |     0.3      | 0.027523  |\n",
      "| 1152934  |     0.1      | 0.018868  |\n",
      "|  387874  |     0.2      | 0.052632  |\n",
      "| 2291272  |     0.7      | 0.049645  |\n",
      "| 3411123  |     0.1      | 0.014286  |\n",
      "| 4165406  |     0.3      | 0.050847  |\n",
      "| 2418598  |     0.1      | 0.011111  |\n",
      "| 3496147  |     0.6      | 0.073171  |\n",
      "| 2452795  |     0.2      | 0.031746  |\n",
      "|  225575  |     0.5      | 0.051546  |\n",
      "| 2838988  |     0.5      | 0.079365  |\n",
      "|  456214  |     0.1      | 0.012987  |\n",
      "|  761742  |     0.6      | 0.240000  |\n",
      "| 3825386  |     0.1      | 0.010638  |\n",
      "| 2443586  |     0.9      | 0.103448  |\n",
      "|  172731  |     0.3      | 0.035294  |\n",
      "| 2783398  |     0.7      | 0.059322  |\n",
      "|  402514  |     0.4      | 0.057971  |\n",
      "| 4278201  |     0.5      | 0.083333  |\n",
      "| 2539741  |     0.1      | 0.009901  |\n",
      "| 3714728  |     0.6      | 0.109091  |\n",
      "| 3778229  |     0.7      | 0.120690  |\n",
      "| 3640705  |     0.3      | 0.035294  |\n",
      "| 1077370  |     0.4      | 0.070175  |\n",
      "| 1373069  |     0.1      | 0.015625  |\n",
      "| 1063812  |     0.3      | 0.023622  |\n",
      "| 2722241  |     0.1      | 0.011494  |\n",
      "|  746920  |     0.3      | 0.024390  |\n",
      "| 1977054  |     0.5      | 0.084746  |\n",
      "| 1199639  |     0.3      | 0.025862  |\n",
      "| 2785579  |     0.0      | 0.000000  |\n",
      "| 1964316  |     0.6      | 0.076923  |\n",
      "| 3206998  |     0.6      | 0.086957  |\n",
      "| 2864267  |     0.6      | 0.063830  |\n",
      "| 3382736  |     1.0      | 0.272727  |\n",
      "|  949154  |     0.3      | 0.044118  |\n",
      "| 1364894  |     0.6      | 0.074074  |\n",
      "| 2797224  |     0.1      | 0.011364  |\n",
      "|  765138  |     0.5      | 0.066667  |\n",
      "| 2479423  |     0.4      | 0.043011  |\n",
      "| 2862887  |     0.1      | 0.016667  |\n",
      "| 4250296  |     0.1      | 0.015625  |\n",
      "| 3872395  |     0.0      | 0.000000  |\n",
      "| 4473137  |     0.1      | 0.020833  |\n",
      "| 1509982  |     0.1      | 0.016393  |\n",
      "| 3269759  |     0.4      | 0.064516  |\n",
      "| 3723508  |     0.8      | 0.166667  |\n",
      "| 1282199  |     0.5      | 0.066667  |\n",
      "| 4196421  |     0.7      | 0.166667  |\n",
      "| 1850323  |     0.0      | 0.000000  |\n",
      "| 2192891  |     0.3      | 0.036585  |\n",
      "| 4406669  |     0.8      | 0.038095  |\n",
      "| 1582877  |     0.0      | 0.000000  |\n",
      "| 1340574  |     0.6      | 0.055556  |\n",
      "| 1971899  |     0.0      | 0.000000  |\n",
      "+----------+--------------+-----------+\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "id": "4a58b1e20dce9431",
   "metadata": {},
   "source": [
    "# 8. Improving Results With Embedding\n",
    "new matcher class for embedding models, the matcher class will load embedding model on initialization"
   ]
  },
  {
   "cell_type": "code",
   "id": "30e709fa005a1a01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T13:30:24.435484Z",
     "start_time": "2024-06-01T13:30:24.418126Z"
    }
   },
   "source": [
    "class BaseEmbeddingMatcher:\n",
    "\n",
    "    def __init__(self, model_name: str, text_processor: BaseTextProcessor):\n",
    "        self.vector_collection = ChromaHelper.get_instance().get_or_create_collection(model_name)\n",
    "        self.vector_size = int(os.environ.get(\"VECTOR_SIZE\", 500))\n",
    "        self.model: Word2Vec = self.__load_model(model_name)\n",
    "        self.text_processor = text_processor\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def match(self, text: str, top: int = 5000):\n",
    "        processed_query: List[str] = self.text_processor.process(text)\n",
    "        query_embeddings: List = self.vectorize_query(processed_query).tolist()\n",
    "\n",
    "        result = self.vector_collection.query(\n",
    "            query_embeddings=query_embeddings,\n",
    "            n_results=top,\n",
    "        )\n",
    "\n",
    "        transformed_results = []\n",
    "        ids = result.get('ids', [[]])[0]\n",
    "        documents = result.get('documents', [[]])[0]\n",
    "        distances = result.get('distances', [[]])[0]\n",
    "\n",
    "        for doc_id, doc_content, doc_similarity in zip(ids, documents, distances):\n",
    "            transformed_results.append({\n",
    "                'doc_id': doc_id,\n",
    "                'doc_content': doc_content,\n",
    "                'similarity': doc_similarity,\n",
    "            })\n",
    "\n",
    "        return transformed_results\n",
    "\n",
    "    def vectorize_query(self, query_words: list[str]) -> ndarray:\n",
    "\n",
    "        query_vectors = [self.model.wv[word] for word in query_words if word in self.model.wv ]\n",
    "\n",
    "        if query_vectors:\n",
    "            query_vec = np.mean(query_vectors, axis=0)\n",
    "        else:\n",
    "            query_vec = np.zeros(self.vector_size)\n",
    "\n",
    "        return query_vec\n",
    "\n",
    "    @staticmethod\n",
    "    def __load_model(model_name: str):\n",
    "        return FileUtilities.load_file(\n",
    "            file_path=Locations.generate_embeddings_model_path(model_name)\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "class AntiqueEmbeddingMatcher(BaseEmbeddingMatcher):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            model_name='antique',\n",
    "            text_processor=AntiqueTextProcessor()\n",
    "        )"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "id": "3643c6091f2c5efe",
   "metadata": {},
   "source": [
    "### 9. Results (With Embedding)\n",
    "- ~10%+ MAP \n",
    "- ~10%+ MRR"
   ]
  },
  {
   "cell_type": "code",
   "id": "63af15ac701754a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T13:34:14.612607Z",
     "start_time": "2024-06-01T13:33:00.086553Z"
    }
   },
   "source": [
    "\n",
    "matcher = AntiqueEmbeddingMatcher()\n",
    "evaluation_manager = EvaluationManager(metric_calculators, matcher)\n",
    "evaluation_results_with_embedding = evaluation_manager.evaluate(queries, qrels, RECALL_PRECISION_THRESHOLD)\n",
    "\n",
    "average_map_with_embedding, average_mrr_with_embedding = calculate_average_metrics(evaluation_results_with_embedding)\n",
    "print(f\"MAP with embedding: {average_map_with_embedding:.6f}\")\n",
    "print(f\"MRR with embedding: {average_mrr_with_embedding:.6f}\")\n",
    "\n",
    "table = []\n",
    "for query_id, metrics in evaluation_results_with_embedding.items():\n",
    "    row = [\n",
    "        query_id,\n",
    "        f\"{metrics['PrecisionCalculator']}\",\n",
    "        f\"{metrics['RecallCalculator']:.6f}\"\n",
    "    ]\n",
    "    table.append(row)\n",
    "\n",
    "print(\"\\nDetailed Results With Embedding:\")\n",
    "print(tabulate(table, headers=[\"Query ID\", f'Precision@{RECALL_PRECISION_THRESHOLD}', f'Recall@{RECALL_PRECISION_THRESHOLD}'], tablefmt=\"pretty\"))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP with embedding: 0.705983\n",
      "MRR with embedding: 0.801345\n",
      "\n",
      "Detailed Results With Embedding:\n",
      "+----------+--------------+-----------+\n",
      "| Query ID | Precision@10 | Recall@10 |\n",
      "+----------+--------------+-----------+\n",
      "| 3990512  |     0.8      | 0.109589  |\n",
      "|  714612  |     0.6      | 0.085714  |\n",
      "| 2528767  |     0.8      | 0.111111  |\n",
      "|  821387  |     0.0      | 0.000000  |\n",
      "| 1880028  |     0.5      | 0.074627  |\n",
      "| 4448097  |     0.5      | 0.069444  |\n",
      "| 1287437  |     0.5      | 0.063291  |\n",
      "| 2956570  |     0.6      | 0.107143  |\n",
      "| 1351675  |     0.4      | 0.075472  |\n",
      "| 1783010  |     0.1      | 0.019608  |\n",
      "| 2799913  |     0.3      | 0.033708  |\n",
      "| 2142044  |     0.5      | 0.106383  |\n",
      "|  707303  |     0.5      | 0.064935  |\n",
      "|  676028  |     0.5      | 0.076923  |\n",
      "| 2484180  |     0.6      | 0.075949  |\n",
      "| 2307305  |     0.4      | 0.054795  |\n",
      "| 2814599  |     0.7      | 0.155556  |\n",
      "| 3369088  |     0.7      | 0.065421  |\n",
      "| 1702151  |     0.2      | 0.037037  |\n",
      "|  851124  |     0.9      | 0.121622  |\n",
      "| 3698636  |     0.0      | 0.000000  |\n",
      "| 1844896  |     0.5      | 0.079365  |\n",
      "| 2290758  |     0.3      | 0.035294  |\n",
      "|  143833  |     0.6      | 0.107143  |\n",
      "| 3910925  |     0.5      | 0.042017  |\n",
      "| 2643507  |     0.7      | 0.088608  |\n",
      "| 1502604  |     0.2      | 0.032258  |\n",
      "| 4283542  |     0.7      | 0.109375  |\n",
      "| 3554263  |     0.2      | 0.022472  |\n",
      "| 3313308  |     0.1      | 0.010870  |\n",
      "| 4357460  |     0.5      | 0.051546  |\n",
      "| 2582920  |     1.0      | 0.117647  |\n",
      "| 4462511  |     0.6      | 0.120000  |\n",
      "| 2795030  |     0.4      | 0.049383  |\n",
      "|  312215  |     0.8      | 0.126984  |\n",
      "| 3363149  |     0.5      | 0.092593  |\n",
      "| 1944018  |     0.1      | 0.008547  |\n",
      "|  788976  |     0.4      | 0.036036  |\n",
      "| 4385316  |     0.3      | 0.040541  |\n",
      "|  551239  |     0.7      | 0.095890  |\n",
      "| 3499881  |     0.4      | 0.042553  |\n",
      "| 4311093  |     0.8      | 0.086957  |\n",
      "| 4256593  |     0.8      | 0.131148  |\n",
      "| 1017690  |     0.6      | 0.125000  |\n",
      "|  667488  |     1.0      | 0.270270  |\n",
      "| 3507491  |     0.5      | 0.060241  |\n",
      "| 2634143  |     0.8      | 0.186047  |\n",
      "| 3396066  |     0.1      | 0.009901  |\n",
      "| 2892478  |     0.7      | 0.109375  |\n",
      "| 3155314  |     0.3      | 0.062500  |\n",
      "|  785823  |     0.5      | 0.079365  |\n",
      "| 2815090  |     0.5      | 0.090909  |\n",
      "| 2713171  |     0.0      | 0.000000  |\n",
      "| 1821193  |     0.4      | 0.049383  |\n",
      "| 4185501  |     0.2      | 0.020202  |\n",
      "| 4473331  |     0.1      | 0.014706  |\n",
      "| 4190287  |     0.3      | 0.044776  |\n",
      "| 1937374  |     0.3      | 0.044118  |\n",
      "| 1459749  |     0.6      | 0.127660  |\n",
      "|  23464   |     0.3      | 0.053571  |\n",
      "| 4377861  |     0.6      | 0.260870  |\n",
      "| 3385681  |     0.4      | 0.036036  |\n",
      "| 1794677  |     0.4      | 0.050000  |\n",
      "| 3301173  |     0.6      | 0.127660  |\n",
      "|  204633  |     0.6      | 0.092308  |\n",
      "| 3960080  |     0.8      | 0.153846  |\n",
      "| 1262692  |     0.5      | 0.051020  |\n",
      "|  558570  |     0.5      | 0.072464  |\n",
      "| 1167882  |     0.6      | 0.101695  |\n",
      "| 3295055  |     0.3      | 0.042857  |\n",
      "|  100653  |     0.7      | 0.116667  |\n",
      "| 2619912  |     0.5      | 0.054945  |\n",
      "| 1663853  |     0.2      | 0.023256  |\n",
      "| 2592121  |     0.7      | 0.094595  |\n",
      "| 2182052  |     0.7      | 0.129630  |\n",
      "| 1623623  |     0.5      | 0.073529  |\n",
      "| 3078448  |     0.9      | 0.072000  |\n",
      "| 3074429  |     0.5      | 0.051020  |\n",
      "| 1119420  |     0.8      | 0.098765  |\n",
      "| 1290612  |     0.6      | 0.072289  |\n",
      "| 2529114  |     0.7      | 0.066038  |\n",
      "|  204963  |     0.0      | 0.000000  |\n",
      "| 4367654  |     0.6      | 0.083333  |\n",
      "| 3639660  |     0.3      | 0.069767  |\n",
      "| 4197214  |     0.8      | 0.097561  |\n",
      "| 1015624  |     0.6      | 0.095238  |\n",
      "| 1082595  |     0.6      | 0.115385  |\n",
      "| 3239329  |     0.6      | 0.090909  |\n",
      "| 3874326  |     0.1      | 0.015625  |\n",
      "| 1254390  |     0.6      | 0.071429  |\n",
      "| 4018891  |     1.0      | 0.048309  |\n",
      "| 3552010  |     0.2      | 0.027027  |\n",
      "| 1968489  |     0.1      | 0.013514  |\n",
      "|  443848  |     0.7      | 0.106061  |\n",
      "| 4372730  |     0.0      | 0.000000  |\n",
      "|  896725  |     0.1      | 0.011494  |\n",
      "| 2180086  |     0.1      | 0.022727  |\n",
      "|  34041   |     0.5      | 0.048544  |\n",
      "|  229303  |     0.4      | 0.043011  |\n",
      "| 2446614  |     0.4      | 0.040404  |\n",
      "|  654124  |     0.4      | 0.050633  |\n",
      "| 3577501  |     0.7      | 0.107692  |\n",
      "|   8293   |     0.2      | 0.032787  |\n",
      "| 4012558  |     0.6      | 0.095238  |\n",
      "|  922849  |     0.7      | 0.049296  |\n",
      "| 2976644  |     0.5      | 0.079365  |\n",
      "| 1866981  |     0.1      | 0.008264  |\n",
      "| 4467100  |     0.0      | 0.000000  |\n",
      "| 2551845  |     0.3      | 0.032258  |\n",
      "| 3559048  |     1.0      | 0.151515  |\n",
      "|  823384  |     0.3      | 0.061224  |\n",
      "|  849221  |     0.4      | 0.037037  |\n",
      "| 3280768  |     0.7      | 0.074468  |\n",
      "| 4288761  |     0.3      | 0.032258  |\n",
      "| 2847807  |     0.2      | 0.022472  |\n",
      "| 2018562  |     0.4      | 0.057143  |\n",
      "| 1035857  |     0.5      | 0.056180  |\n",
      "| 2008017  |     0.5      | 0.062500  |\n",
      "| 1862795  |     0.4      | 0.080000  |\n",
      "|  421753  |     0.0      | 0.000000  |\n",
      "| 1477322  |     0.3      | 0.042857  |\n",
      "| 1607728  |     0.8      | 0.112676  |\n",
      "|  103830  |     0.7      | 0.106061  |\n",
      "| 3971195  |     0.9      | 0.070312  |\n",
      "| 4153592  |     0.0      | 0.000000  |\n",
      "| 2382487  |     0.4      | 0.027211  |\n",
      "| 2380990  |     0.5      | 0.056818  |\n",
      "|  484496  |     0.5      | 0.065789  |\n",
      "| 4003223  |     0.7      | 0.098592  |\n",
      "| 4185395  |     0.8      | 0.094118  |\n",
      "| 1292734  |     0.0      | 0.000000  |\n",
      "| 3389038  |     0.2      | 0.023256  |\n",
      "|  474417  |     0.5      | 0.072464  |\n",
      "| 3278654  |     0.7      | 0.074468  |\n",
      "| 4365565  |     0.4      | 0.052632  |\n",
      "|  354733  |     0.4      | 0.061538  |\n",
      "|  224109  |     0.0      | 0.000000  |\n",
      "| 4126337  |     0.2      | 0.034483  |\n",
      "| 1957887  |     0.2      | 0.027397  |\n",
      "|  78762   |     0.0      | 0.000000  |\n",
      "|  159716  |     0.5      | 0.066667  |\n",
      "|  481173  |     0.6      | 0.060000  |\n",
      "| 2814722  |     0.7      | 0.078652  |\n",
      "| 3040435  |     0.5      | 0.102041  |\n",
      "|  953489  |     0.1      | 0.015873  |\n",
      "| 2309774  |     0.5      | 0.045872  |\n",
      "| 1152934  |     0.1      | 0.018868  |\n",
      "|  387874  |     0.4      | 0.105263  |\n",
      "| 2291272  |     0.7      | 0.049645  |\n",
      "| 3411123  |     0.1      | 0.014286  |\n",
      "| 4165406  |     0.6      | 0.101695  |\n",
      "| 2418598  |     0.4      | 0.044444  |\n",
      "| 3496147  |     0.4      | 0.048780  |\n",
      "| 2452795  |     0.3      | 0.047619  |\n",
      "|  225575  |     0.7      | 0.072165  |\n",
      "| 2838988  |     0.9      | 0.142857  |\n",
      "|  456214  |     0.8      | 0.103896  |\n",
      "|  761742  |     0.1      | 0.040000  |\n",
      "| 3825386  |     0.2      | 0.021277  |\n",
      "| 2443586  |     0.7      | 0.080460  |\n",
      "|  172731  |     0.7      | 0.082353  |\n",
      "| 2783398  |     0.8      | 0.067797  |\n",
      "|  402514  |     0.4      | 0.057971  |\n",
      "| 4278201  |     0.9      | 0.150000  |\n",
      "| 2539741  |     0.3      | 0.029703  |\n",
      "| 3714728  |     0.4      | 0.072727  |\n",
      "| 3778229  |     0.8      | 0.137931  |\n",
      "| 3640705  |     0.4      | 0.047059  |\n",
      "| 1077370  |     0.7      | 0.122807  |\n",
      "| 1373069  |     0.2      | 0.031250  |\n",
      "| 1063812  |     0.3      | 0.023622  |\n",
      "| 2722241  |     0.2      | 0.022989  |\n",
      "|  746920  |     0.7      | 0.056911  |\n",
      "| 1977054  |     0.4      | 0.067797  |\n",
      "| 1199639  |     0.8      | 0.068966  |\n",
      "| 2785579  |     0.1      | 0.014925  |\n",
      "| 1964316  |     0.7      | 0.089744  |\n",
      "| 3206998  |     0.5      | 0.072464  |\n",
      "| 2864267  |     0.8      | 0.085106  |\n",
      "| 3382736  |     0.3      | 0.136364  |\n",
      "|  949154  |     0.6      | 0.088235  |\n",
      "| 1364894  |     0.8      | 0.098765  |\n",
      "| 2797224  |     0.2      | 0.022727  |\n",
      "|  765138  |     0.7      | 0.093333  |\n",
      "| 2479423  |     0.6      | 0.064516  |\n",
      "| 2862887  |     0.5      | 0.083333  |\n",
      "| 4250296  |     0.5      | 0.078125  |\n",
      "| 3872395  |     0.1      | 0.012821  |\n",
      "| 4473137  |     0.1      | 0.020833  |\n",
      "| 1509982  |     0.6      | 0.098361  |\n",
      "| 3269759  |     0.4      | 0.064516  |\n",
      "| 3723508  |     0.9      | 0.187500  |\n",
      "| 1282199  |     0.6      | 0.080000  |\n",
      "| 4196421  |     0.2      | 0.047619  |\n",
      "| 1850323  |     0.2      | 0.019417  |\n",
      "| 2192891  |     0.5      | 0.060976  |\n",
      "| 4406669  |     0.8      | 0.038095  |\n",
      "| 1582877  |     0.2      | 0.019608  |\n",
      "| 1340574  |     0.8      | 0.074074  |\n",
      "| 1971899  |     0.1      | 0.033333  |\n",
      "+----------+--------------+-----------+\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 10. More Examples",
   "id": "c84b1b6e337ac290"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T13:54:10.376527Z",
     "start_time": "2024-06-01T13:54:09.134224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = AntiqueMatcher().match(query='how to clear browser history')[:10]\n",
    "table_data = [(result['doc_id'], result['doc_content']) for result in results]\n",
    "print(tabulate(table_data, headers=[\"Doc ID\", \"Content\"], tablefmt=\"grid\"))"
   ],
   "id": "3e33edc5f6a61b12",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------------------------------------------------------------------------------------------------+\n",
      "|     Doc ID | Content                                                                                             |\n",
      "+============+=====================================================================================================+\n",
      "|  4471405_1 | It is in the history of your browser.                                                               |\n",
      "+------------+-----------------------------------------------------------------------------------------------------+\n",
      "|   449748_1 | Yes:. 1)Open your browser. 2)Tools. 3)Internet Options. 4)Clear History                             |\n",
      "+------------+-----------------------------------------------------------------------------------------------------+\n",
      "|   449748_4 | it depends on what browser you have                                                                 |\n",
      "+------------+-----------------------------------------------------------------------------------------------------+\n",
      "|   449748_3 | At your browser > Go to Tools > internet options > Under the General Tab, Click on Clear history... |\n",
      "+------------+-----------------------------------------------------------------------------------------------------+\n",
      "|   890594_0 | which browser ru using , and downloads r in temporary browsers                                      |\n",
      "+------------+-----------------------------------------------------------------------------------------------------+\n",
      "|  3194482_2 | Put his name in your browser. He is famous.                                                         |\n",
      "+------------+-----------------------------------------------------------------------------------------------------+\n",
      "| 2552144_11 | go to history and select clear search history                                                       |\n",
      "+------------+-----------------------------------------------------------------------------------------------------+\n",
      "|  2727757_7 | Because it is clear?                                                                                |\n",
      "+------------+-----------------------------------------------------------------------------------------------------+\n",
      "|  3624479_3 | that it is not clear to you at all                                                                  |\n",
      "+------------+-----------------------------------------------------------------------------------------------------+\n",
      "|  3624479_5 | it's not clear at all                                                                               |\n",
      "+------------+-----------------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T13:54:12.420206Z",
     "start_time": "2024-06-01T13:54:10.379534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = AntiqueMatcher().match(query='is doing trading risky?')[:10]\n",
    "table_data = [(result['doc_id'], result['doc_content']) for result in results]\n",
    "print(tabulate(table_data, headers=[\"Doc ID\", \"Content\"], tablefmt=\"grid\"))"
   ],
   "id": "1014363452abba42",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------------------------------------------------------------+\n",
      "|    Doc ID | Content                                                                |\n",
      "+===========+========================================================================+\n",
      "| 2625406_1 | funny!  You don't.  Day trading is VERY risky no matter how you do it. |\n",
      "+-----------+------------------------------------------------------------------------+\n",
      "| 2625406_2 | RiSKY!                                                                 |\n",
      "+-----------+------------------------------------------------------------------------+\n",
      "|   67596_3 | TOO MUCH OF ANYTHING IS HAZARDOUS                                      |\n",
      "+-----------+------------------------------------------------------------------------+\n",
      "| 1085433_0 | just go to the trading house and ask them.                             |\n",
      "+-----------+------------------------------------------------------------------------+\n",
      "| 2392180_1 | It's very popular and also very risky.                                 |\n",
      "+-----------+------------------------------------------------------------------------+\n",
      "| 1343068_3 | investment...but it is risky!                                          |\n",
      "+-----------+------------------------------------------------------------------------+\n",
      "| 3029610_6 | Its about currency trading.                                            |\n",
      "+-----------+------------------------------------------------------------------------+\n",
      "| 1039931_1 | You don't...it's a risky investment.                                   |\n",
      "+-----------+------------------------------------------------------------------------+\n",
      "|  782045_4 | By trading it in for something better!. . DON'T BUY FRENCH!            |\n",
      "+-----------+------------------------------------------------------------------------+\n",
      "| 1724673_7 | both are risky things. need to be handled with care                    |\n",
      "+-----------+------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T13:54:12.428207Z",
     "start_time": "2024-06-01T13:54:12.424215Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "696b1627112f229f",
   "outputs": [],
   "execution_count": 56
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
